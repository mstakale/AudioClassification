{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file_name):\n",
    "    \n",
    "    audio,sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfcc_feat = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    pad_width = max_pad_len - mfcc_feat.shape[1]\n",
    "    mfcc_feat = np.pad(mfcc_feat, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    \n",
    "    return mfcc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105835,)\n",
      "(105835,)\n"
     ]
    }
   ],
   "source": [
    "home_path = '/Users/manishatakale/Downloads/mlchallenge/'\n",
    "\n",
    "os.chdir(home_path)\n",
    "\n",
    "feat = np.load('feat.npy' , allow_pickle=True)\n",
    "path = np.load('path.npy' , allow_pickle=True)\n",
    "\n",
    "print(feat.shape)\n",
    "print(path.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 99\n",
    "features = []\n",
    "\n",
    "data = pd.read_csv(home_path + 'train.csv')\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(home_path + '/wav/')+ '/' + str(row[\"path\"]))\n",
    "    \n",
    "    class_label = row[\"word\"]\n",
    "    data = get_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  94824  files\n"
     ]
    }
   ],
   "source": [
    "# Convert into a Panda dataframe \n",
    "new_features = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(new_features), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[-537.57043, -522.28406, -524.77997, -546.343...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[-519.0905, -513.495, -514.77966, -514.9921, ...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[-558.69073, -559.25275, -558.4838, -557.4996...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[[-541.83777, -535.3056, -527.8647, -532.6044,...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[[-606.06976, -609.54034, -615.7957, -618.5272...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature class_label\n",
       "0  [[-537.57043, -522.28406, -524.77997, -546.343...         one\n",
       "1  [[-519.0905, -513.495, -514.77966, -514.9921, ...         one\n",
       "2  [[-558.69073, -559.25275, -558.4838, -557.4996...         one\n",
       "3  [[-541.83777, -535.3056, -527.8647, -532.6044,...         one\n",
       "4  [[-606.06976, -609.54034, -615.7957, -618.5272...         one"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(new_features.feature.tolist())\n",
    "y = np.array(new_features.class_label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94824, 40, 99)\n",
      "(94824,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75859, 40, 99)\n",
      "(18965, 40, 99)\n",
      "(75859, 35)\n",
      "(18965, 35)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 99\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],  num_columns, num_rows,num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0],  num_columns,num_rows,num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75859, 99, 40, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18965, 99, 40, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##very basic model\n",
    "\n",
    "M = Sequential()\n",
    "M.add(Flatten(input_shape = (num_columns, num_rows,num_channels)))\n",
    "M.add(Dense(num_labels, activation = 'softmax'))\n",
    "M.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.fit(x_train,y_train, epochs=50 , validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding one  layers\n",
    "\n",
    "M = Sequential()\n",
    "M.add(Conv2D(32,(3,3), input_shape = (num_columns, num_rows,num_channels),activation = \"relu\"))\n",
    "M.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "M.add(Flatten())\n",
    "M.add(Dense(128,activation='relu'))\n",
    "M.add(Dense(num_labels, activation = 'softmax'))\n",
    "\n",
    "M.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.fit(x_train,y_train, epochs=10 , validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding two layer Conv2D Model\n",
    "\n",
    "M = Sequential()\n",
    "M.add(Conv2D(32,(3,3), input_shape = (num_columns, num_rows,num_channels),activation = \"relu\"))\n",
    "M.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "M.add(Conv2D(32,(3,3),activation = \"relu\"))\n",
    "M.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "M.add(Flatten())\n",
    "M.add(Dense(128,activation='relu'))\n",
    "M.add(Dense(num_labels, activation = 'softmax'))\n",
    "M.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75859 samples, validate on 18965 samples\n",
      "Epoch 1/10\n",
      "75859/75859 [==============================] - 284s 4ms/step - loss: 1.7185 - accuracy: 0.5192 - val_loss: 1.1840 - val_accuracy: 0.6557\n",
      "Epoch 2/10\n",
      "75859/75859 [==============================] - 296s 4ms/step - loss: 0.9170 - accuracy: 0.7297 - val_loss: 0.9438 - val_accuracy: 0.7259\n",
      "Epoch 3/10\n",
      "75859/75859 [==============================] - 462s 6ms/step - loss: 0.6902 - accuracy: 0.7935 - val_loss: 0.9183 - val_accuracy: 0.7394\n",
      "Epoch 4/10\n",
      "75859/75859 [==============================] - 286s 4ms/step - loss: 0.5438 - accuracy: 0.8331 - val_loss: 0.9470 - val_accuracy: 0.7441\n",
      "Epoch 5/10\n",
      "75859/75859 [==============================] - 299s 4ms/step - loss: 0.4392 - accuracy: 0.8630 - val_loss: 1.0233 - val_accuracy: 0.7414\n",
      "Epoch 6/10\n",
      "75859/75859 [==============================] - 319s 4ms/step - loss: 0.3610 - accuracy: 0.8861 - val_loss: 1.1445 - val_accuracy: 0.7423\n",
      "Epoch 7/10\n",
      "75859/75859 [==============================] - 300s 4ms/step - loss: 0.3032 - accuracy: 0.9046 - val_loss: 1.2776 - val_accuracy: 0.7321\n",
      "Epoch 8/10\n",
      "75859/75859 [==============================] - 297s 4ms/step - loss: 0.2575 - accuracy: 0.9183 - val_loss: 1.4086 - val_accuracy: 0.7351\n",
      "Epoch 9/10\n",
      "75859/75859 [==============================] - 303s 4ms/step - loss: 0.2289 - accuracy: 0.9277 - val_loss: 1.5061 - val_accuracy: 0.7298\n",
      "Epoch 10/10\n",
      "75859/75859 [==============================] - 302s 4ms/step - loss: 0.2016 - accuracy: 0.9366 - val_loss: 1.6465 - val_accuracy: 0.7323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cf1ee8810>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.fit(x_train,y_train, epochs=10 , validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
